{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5I-jL_h4JV_"
   },
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWKH2JTr4JWJ"
   },
   "source": [
    "### WORKFLOW :\n",
    "- Load Data\n",
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column.\n",
    "- Shuffle the data if needed.\n",
    "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
    "- Split into 60 and 40 ratio.\n",
    "- Encode labels.\n",
    "- Model : 1 hidden layers including 16 unit.\n",
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "- Train the Model with Epochs (100).\n",
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**\n",
    "- Evaluation Step\n",
    "- Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5GZOR6o4JWK"
   },
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nwM0utP24JWK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers,optimizers,utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uEGNQoCS4JWL"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/content/ionosphere_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ECAiy1aL4JWL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224.0
    },
    "outputId": "7e96ae43-ad9f-4bd7-8f9c-56deb25d19c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>feature22</th>\n",
       "      <th>feature23</th>\n",
       "      <th>feature24</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>-0.17755</td>\n",
       "      <td>0.59755</td>\n",
       "      <td>-0.44945</td>\n",
       "      <td>0.60536</td>\n",
       "      <td>-0.38223</td>\n",
       "      <td>0.84356</td>\n",
       "      <td>-0.38542</td>\n",
       "      <td>0.58212</td>\n",
       "      <td>-0.32192</td>\n",
       "      <td>0.56971</td>\n",
       "      <td>-0.29674</td>\n",
       "      <td>0.36946</td>\n",
       "      <td>-0.47357</td>\n",
       "      <td>0.56811</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>-0.67743</td>\n",
       "      <td>0.34432</td>\n",
       "      <td>-0.69707</td>\n",
       "      <td>-0.51685</td>\n",
       "      <td>-0.97515</td>\n",
       "      <td>0.05499</td>\n",
       "      <td>-0.62237</td>\n",
       "      <td>0.33109</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.13151</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>-0.18056</td>\n",
       "      <td>-0.35734</td>\n",
       "      <td>-0.20332</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>0.05346</td>\n",
       "      <td>0.85443</td>\n",
       "      <td>0.00827</td>\n",
       "      <td>0.54591</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>0.83775</td>\n",
       "      <td>-0.13644</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>-0.08540</td>\n",
       "      <td>0.70887</td>\n",
       "      <td>-0.27502</td>\n",
       "      <td>0.43385</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.57528</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.14516</td>\n",
       "      <td>0.54094</td>\n",
       "      <td>-0.39330</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.54467</td>\n",
       "      <td>-0.69975</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>-0.20275</td>\n",
       "      <td>0.56409</td>\n",
       "      <td>-0.00712</td>\n",
       "      <td>0.34395</td>\n",
       "      <td>-0.27457</td>\n",
       "      <td>0.52940</td>\n",
       "      <td>-0.21780</td>\n",
       "      <td>0.45107</td>\n",
       "      <td>-0.17813</td>\n",
       "      <td>0.05982</td>\n",
       "      <td>-0.35575</td>\n",
       "      <td>0.02309</td>\n",
       "      <td>-0.52879</td>\n",
       "      <td>0.03286</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  ...  feature33  feature34  label\n",
       "0         1         0   0.99539  ...    0.18641   -0.45300      g\n",
       "1         1         0   1.00000  ...   -0.13738   -0.02447      b\n",
       "2         1         0   1.00000  ...    0.56045   -0.38238      g\n",
       "3         1         0   1.00000  ...   -0.32382    1.00000      b\n",
       "4         1         0   1.00000  ...   -0.04608   -0.65697      g\n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJsQdI6i4pRw"
   },
   "source": [
    "Check Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aRv5voc84rH6"
   },
   "outputs": [],
   "source": [
    "# creating a dataframe from list\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "#CHECK MISSING VALUE if exist replace it with mean\n",
    "if df.isnull:\n",
    "  df.fillna(df.mean())\n",
    "  df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJdgDSUP4okL"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y3_gDdyz4JWN",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224.0
    },
    "outputId": "8f7c1210-c54f-4be7-a108-e8492eed46b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>feature22</th>\n",
       "      <th>feature23</th>\n",
       "      <th>feature24</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>0.89391</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.81197</td>\n",
       "      <td>0.06723</td>\n",
       "      <td>0.79307</td>\n",
       "      <td>-0.08929</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02101</td>\n",
       "      <td>0.96639</td>\n",
       "      <td>0.06618</td>\n",
       "      <td>0.87605</td>\n",
       "      <td>0.01155</td>\n",
       "      <td>0.77521</td>\n",
       "      <td>0.06618</td>\n",
       "      <td>0.95378</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>0.96510</td>\n",
       "      <td>0.03281</td>\n",
       "      <td>0.94171</td>\n",
       "      <td>0.07330</td>\n",
       "      <td>0.94625</td>\n",
       "      <td>-0.01326</td>\n",
       "      <td>0.97173</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>0.94834</td>\n",
       "      <td>0.06038</td>\n",
       "      <td>0.92670</td>\n",
       "      <td>0.08412</td>\n",
       "      <td>0.93124</td>\n",
       "      <td>0.10087</td>\n",
       "      <td>0.94520</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>0.94124</td>\n",
       "      <td>0.01766</td>\n",
       "      <td>0.92595</td>\n",
       "      <td>0.04688</td>\n",
       "      <td>0.93954</td>\n",
       "      <td>-0.01461</td>\n",
       "      <td>0.94837</td>\n",
       "      <td>0.02004</td>\n",
       "      <td>0.93784</td>\n",
       "      <td>0.01393</td>\n",
       "      <td>0.91406</td>\n",
       "      <td>0.07677</td>\n",
       "      <td>0.89470</td>\n",
       "      <td>0.06148</td>\n",
       "      <td>0.93988</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>0.89724</td>\n",
       "      <td>-0.03315</td>\n",
       "      <td>0.89061</td>\n",
       "      <td>-0.01436</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.04530</td>\n",
       "      <td>0.91381</td>\n",
       "      <td>-0.00884</td>\n",
       "      <td>0.80773</td>\n",
       "      <td>-0.12928</td>\n",
       "      <td>0.88729</td>\n",
       "      <td>0.01215</td>\n",
       "      <td>0.92155</td>\n",
       "      <td>-0.02320</td>\n",
       "      <td>0.91050</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>0.78735</td>\n",
       "      <td>0.06678</td>\n",
       "      <td>0.80668</td>\n",
       "      <td>-0.00351</td>\n",
       "      <td>0.79262</td>\n",
       "      <td>-0.01054</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.04569</td>\n",
       "      <td>0.87170</td>\n",
       "      <td>-0.03515</td>\n",
       "      <td>0.81722</td>\n",
       "      <td>-0.09490</td>\n",
       "      <td>0.71002</td>\n",
       "      <td>0.04394</td>\n",
       "      <td>0.86467</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature2  feature3  ...  feature33  feature34  label\n",
       "346         1         0   0.83508  ...    0.90546   -0.04307      g\n",
       "347         1         0   0.95113  ...    0.91483    0.04712      g\n",
       "348         1         0   0.94701  ...    0.92697   -0.00577      g\n",
       "349         1         0   0.90608  ...    0.87403   -0.16243      g\n",
       "350         1         0   0.84710  ...    0.85764   -0.06151      g\n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() #last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ganoG-zc4JWO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "12426619-bbf8-47a8-88b4-17f677d9371d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature1   351 non-null    int64  \n",
      " 1   feature2   351 non-null    int64  \n",
      " 2   feature3   351 non-null    float64\n",
      " 3   feature4   351 non-null    float64\n",
      " 4   feature5   351 non-null    float64\n",
      " 5   feature6   351 non-null    float64\n",
      " 6   feature7   351 non-null    float64\n",
      " 7   feature8   351 non-null    float64\n",
      " 8   feature9   351 non-null    float64\n",
      " 9   feature10  351 non-null    float64\n",
      " 10  feature11  351 non-null    float64\n",
      " 11  feature12  351 non-null    float64\n",
      " 12  feature13  351 non-null    float64\n",
      " 13  feature14  351 non-null    float64\n",
      " 14  feature15  351 non-null    float64\n",
      " 15  feature16  351 non-null    float64\n",
      " 16  feature17  351 non-null    float64\n",
      " 17  feature18  351 non-null    float64\n",
      " 18  feature19  351 non-null    float64\n",
      " 19  feature20  351 non-null    float64\n",
      " 20  feature21  351 non-null    float64\n",
      " 21  feature22  351 non-null    float64\n",
      " 22  feature23  351 non-null    float64\n",
      " 23  feature24  351 non-null    float64\n",
      " 24  feature25  351 non-null    float64\n",
      " 25  feature26  351 non-null    float64\n",
      " 26  feature27  351 non-null    float64\n",
      " 27  feature28  351 non-null    float64\n",
      " 28  feature29  351 non-null    float64\n",
      " 29  feature30  351 non-null    float64\n",
      " 30  feature31  351 non-null    float64\n",
      " 31  feature32  351 non-null    float64\n",
      " 32  feature33  351 non-null    float64\n",
      " 33  feature34  351 non-null    float64\n",
      " 34  label      351 non-null    object \n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAolyQ_29f0e"
   },
   "source": [
    "Standardized the Input Variables. Hint: Centeralized the data\n",
    "Split into 60 and 40 ratio.\n",
    "Encode labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6QOt9wAz4JWO"
   },
   "outputs": [],
   "source": [
    "x=df.drop(\"label\",axis=1).copy()\n",
    "y=df[\"label\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dwNv5BsU4JWP"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.6,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qwu4gmf34JWP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ab9a1b16-50a3-4c53-98c1-80fcbdbe8078"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aBtXAYq74JWP"
   },
   "outputs": [],
   "source": [
    "x_train =pd.DataFrame(scaler.transform(x_train),columns=x_train.columns)\n",
    "x_test=pd.DataFrame(scaler.transform(x_test),columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WkEEQoOj4JWQ"
   },
   "outputs": [],
   "source": [
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train = le.transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    return y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uBGxvZy54JWQ"
   },
   "outputs": [],
   "source": [
    "y_train,y_test = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkdC14gy9k_P"
   },
   "source": [
    "Model : 1 hidden layers including 16 unit.\n",
    "Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "Train the Model with Epochs (100).\n",
    "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "Prediction should be > 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dQZBpeFF4JWQ"
   },
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Dense(16,activation=tf.nn.relu,input_shape=(34,)))\n",
    "model.add(layers.Dense(16,activation=tf.nn.relu))\n",
    "model.add(layers.Dense(1,activation=tf.nn.sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EMjeK0TH4JWR"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Rl8hxeAl4JWR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4aeadcd7-21a3-4355-c7d6-e8ced9a6c818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 2ms/step - loss: 0.6619 - acc: 0.5492\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5771 - acc: 0.7037\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5504 - acc: 0.7671\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5300 - acc: 0.7684\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5030 - acc: 0.8127\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4767 - acc: 0.8397\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4584 - acc: 0.8541\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4330 - acc: 0.8984\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4070 - acc: 0.8615\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3704 - acc: 0.9098\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3864 - acc: 0.8979\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3482 - acc: 0.8991\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3508 - acc: 0.8923\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3345 - acc: 0.9080\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3119 - acc: 0.9158\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2908 - acc: 0.9178\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2809 - acc: 0.9295\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2771 - acc: 0.9234\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2341 - acc: 0.9439\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2227 - acc: 0.9378\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2401 - acc: 0.9316\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2318 - acc: 0.9477\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2222 - acc: 0.9373\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2285 - acc: 0.9367\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2037 - acc: 0.9388\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2126 - acc: 0.9362\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2346 - acc: 0.9166\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1837 - acc: 0.9378\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1653 - acc: 0.9566\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1856 - acc: 0.9433\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1673 - acc: 0.9384\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1462 - acc: 0.9675\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1533 - acc: 0.9599\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1595 - acc: 0.9377\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1310 - acc: 0.9713\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1290 - acc: 0.9695\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1293 - acc: 0.9740\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1126 - acc: 0.9888\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1178 - acc: 0.9864\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1260 - acc: 0.9775\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1136 - acc: 0.9905\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0906 - acc: 0.9946\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0872 - acc: 0.9982\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0947 - acc: 0.9982\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0838 - acc: 0.9974\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0931 - acc: 0.9931\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0654 - acc: 0.9964\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0664 - acc: 0.9974\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0782 - acc: 0.9951\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0650 - acc: 0.9974\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9951\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0548 - acc: 0.9974\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0638 - acc: 0.9892\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0584 - acc: 0.9931\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0437 - acc: 0.9988\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0486 - acc: 0.9951\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0525 - acc: 0.9931\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0367 - acc: 0.9974\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0485 - acc: 0.9931\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0351 - acc: 0.9982\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0423 - acc: 0.9931\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0327 - acc: 0.9974\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0419 - acc: 0.9892\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0293 - acc: 0.9982\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0340 - acc: 0.9951\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0284 - acc: 0.9951\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0249 - acc: 0.9982\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0262 - acc: 0.9951\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0226 - acc: 0.9951\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0232 - acc: 0.9951\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0270 - acc: 0.9931\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0215 - acc: 0.9951\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0311 - acc: 0.9892\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0216 - acc: 0.9931\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0167 - acc: 0.9974\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0149 - acc: 0.9974\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0150 - acc: 0.9982\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0112 - acc: 0.9982\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0138 - acc: 0.9974\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0113 - acc: 0.9974\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0093 - acc: 0.9982\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0125 - acc: 0.9951\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0085 - acc: 0.9982\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0098 - acc: 0.9974\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0074 - acc: 0.9988\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0065 - acc: 0.9988\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0078 - acc: 0.9974\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0062 - acc: 0.9974\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0052 - acc: 0.9974\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc5994d1c90>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bNrON4Ls4JWR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "26e5a0d7-0f00-4943-93c5-03b6d9ae429c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3674 - acc: 0.9291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3674112558364868, 0.9290780425071716]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jTgyMFKI4JWS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dd23a930-71a7-423a-a6c2-1e74aee361f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.20536"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "name": "Ionosphere.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
